privacy:
  allow_external_tools: false
  allow_network_calls: false
retrieval:
  top_k: 4
  chunk_size: 1000
  chunk_overlap: 100
llm:
  provider: "ollama"  # or "llama-cpp"
  model: "llama3"
